# 引起计算机的注意并开始对话

> 原文：<https://hackaday.com/2022/11/14/on-getting-a-computers-attention-and-striking-up-a-conversation/>

随着这些年来语音驱动虚拟助手的兴起，人们在公共场合和私人场合与各种电子设备交谈的场景已经变得相当常见。虽然这种语音驱动的界面在很多情况下都非常有用，但它们也带来了复杂性。其中一个是语音助手在待机时听到的触发短语或唤醒词。就像在《星际迷航》中，说出“计算机”会引起计算机的注意，所以我们有我们的“Siri”、“Cortana”和一系列自定义触发短语来启用语音界面。

然而，与《星际迷航》不同的是，我们的虚拟助手不知道我们何时真正想要互动。无法区分上下文，他们会很高兴地回应电视上有人提到他们的触发短语。随后可能是一个荒唐的采购订单或其他恶作剧。这里的实现是基于语音的界面的复杂性，同时仍然缺乏任何自我意识或智能。

另一个问题是语音识别过程本身是非常资源密集型的，这限制了可以在本地设备上执行的处理量。这通常会导致像 [Siri](https://en.wikipedia.org/wiki/Siri) 、 [Alexa](https://en.wikipedia.org/wiki/Amazon_Alexa) 、 [Cortana](https://en.wikipedia.org/wiki/Cortana_(virtual_assistant)) 等语音助手在数据中心处理录制的语音，这显然会涉及隐私问题。

## 只要说我的名字

[![Radio Rex, a delightful 1920s toy for young and old (Credit: Emre Sevinç)](img/45c103b02f1f0d5ec8f7e5c3e3c563dc.png)](https://hackaday.com/wp-content/uploads/2022/11/radio_rex_front.jpg)

Radio Rex, a delightful 1920s toy for young and old (Credit: Emre Sevinç)

激活系统的触发词是一个古老的想法，已知的第一个实际例子大约有一百年的历史了。这是一款名为“雷克斯收音机”的玩具，里面有一只机器狗，它会坐在自己的小狗屋里，直到叫到它的名字。此刻，它会跳出来迎接呼唤它的人。

由于 1910 年代和 1920 年代的可用技术，实现这一点的方式很简单，而且相当有限。本质上，它使用了与“Rex”中元音[eh]大致对应的[共振峰](https://en.wikipedia.org/wiki/Formant)的声能。正如一些人提到的[，Radio Rex 的一个问题是它被调到了 500 Hz，这是一个(平均)成年男性声音发出的元音。](https://www.antiqueradios.com/forums/viewtopic.php?t=96869)

这悲惨地意味着，对于儿童和妇女来说，雷克斯通常会拒绝走出狗屋，除非他们使用一个不同的元音，与他们的声音范围 500 赫兹的频率范围相匹配。即使这样，他们也可能遇到这个玩具的另一个主要问题，即所需的绝对声压。从本质上说，这意味着可能需要一些叫喊才能让雷克斯动起来。

这个玩具有趣的是，在许多方面，老雷克斯与现代 Siri 和朋友们的工作方式没有太大区别。使用麦克风和信号处理硬件和软件而不是机械装置，将他们从待机状态唤醒的触发词没有那么粗糙，但效果是一样的。在低功耗触发搜索模式下，助手的软件会不断地将输入声音样本的共振峰与预定义触发词的声音签名进行比较。

一旦检测到匹配，该机制开始工作，助手将从其数字房子中弹出，并切换到其完整的语音处理模式。在这个阶段，一个独立的助手——就像人们可能在老款汽车中发现的那样——可能会使用一个简单的隐马尔可夫模型( [HMM](https://en.wikipedia.org/wiki/Hidden_Markov_model) )来尝试拼凑用户的意图。这种模型通常是在相当简单的词汇模型上训练的。这种模型将特定于特定的语言，并且通常是区域口音和/或方言，以增加准确性。

## 对狗屋来说太大了

[![The internals of the Radio Rex toy. (Credit: Emre Sevinç)](img/99d7b597e29e07a7ec371381090da0ef.png)](https://hackaday.com/wp-content/uploads/2022/11/radio_rex_back_open.jpg)

The internals of the Radio Rex toy. (Credit: Emre Sevinç)

虽然在同一个系统上运行整个自然语言处理程序会很好，但事实是语音识别仍然非常耗费资源。不仅仅是在处理能力方面，因为即使是基于 HMM 的方法也必须筛选每一句话的数千条概率路径，而且在记忆方面也是如此。根据助手的词汇量，内存模型可以从几十兆字节到几千兆字节甚至太字节。这在最新的智能设备、智能手机或智能电视上显然是不切实际的，这就是为什么这种处理通常被转移到数据中心。

当准确性被认为是更重要的事情时——比如当谷歌助手被问及复杂的查询时 HMM 方法通常被抛弃，取而代之的是较新的长短期记忆( [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) )方法。虽然基于 LSTM 的 rnn 在处理较长的短语方面要好得多，但它们也有更高的处理和内存使用要求。

随着当前语音识别技术向更复杂的神经网络模型发展，这种系统要求似乎不太可能被技术进步所超越。

作为一个参考点，我们可以看看卡耐基梅隆大学开发的类似[CMU·斯芬克斯](https://en.wikipedia.org/wiki/CMU_Sphinx)的项目，它是一个单板计算机级别的基本低端系统，如 Raspberry Pi，可能具有语音识别能力。针对嵌入式系统的版本被称为 PocketSphinx，与其更大的版本一样，使用基于 HMM 的方法。在 Spinx FAQ [中，明确提到](https://cmusphinx.github.io/wiki/faq/)大型词汇表无法在像 Raspberry Pi 这样的 SBC 上工作，因为这些平台上的 RAM 和 CPU 能力有限。

然而，当您将词汇表限制在 1000 个单词左右时，该模型可能正好适合 RAM，并且处理速度足够快，对用户来说似乎是即时的。如果您希望语音驱动的界面在训练数据的限制范围内只具有相当好的准确性，同时只提供有限的交互，这是很好的。在目标是允许用户打开或关闭一些灯的情况下，这可能就足够了。另一方面，如果这个界面被称为“Siri”或“Alexa ”,对这样一个界面的期望会高得多。

本质上，这些虚拟助理应该表现得像他们理解自然语言，理解使用自然语言的上下文，并以与普通文明人类互动预期发生的方式相一致的方式进行回复。毫不奇怪，这是一个艰巨的挑战。将语音识别部分卸载到远程数据中心，并使用记录的语音样本来进一步训练模型是这种需求的自然结果。

## 没有智慧，只是猜测而已

我们人类天生就很擅长的一件事，在我们上学的时候被我们进一步纠缠，叫做“词性标注”，也叫做[语法标注](https://en.wikipedia.org/wiki/Part-of-speech_tagging)。这是我们将一个短语的各个部分量化为其语法成分的地方，包括名词、动词、冠词、形容词等等。这样做对于理解一个句子是必不可少的，因为单词的意思可以根据它们的语法分类而发生很大的变化，特别是在像英语这样的语言中，它通常将名词用作动词，反之亦然。

使用语法标记，我们可以理解句子的意思。然而这并不是这些虚拟助手所做的。相反，使用[维特比算法](https://en.wikipedia.org/wiki/Viterbi_algorithm)(对于 HMMs)或等效的 RNN 方法，确定适合语言模型的特定子集的给定输入的概率。毫无疑问，我们大多数人都知道，这种方法在起作用时感觉几乎很神奇，让你意识到 Siri 在无法找到合适的匹配时就像一袋砖头一样愚蠢。

随着对“智能”语音驱动界面需求的增加，工程师们无疑将不懈努力，寻找更巧妙的方法来提高当今系统的精度。在可预见的未来，现实似乎仍然是语音数据被发送到数据中心，强大的服务器系统可以执行必要的概率曲线拟合，以计算出你在问“嘿，谷歌”最近的冰淇淋店在哪里。不要介意你实际上是在问最近的自行车商店，但那对你来说是技术。

## 说话轻松

关于整个自然语言和计算机交互体验，也许有点讽刺的是，语音合成或多或少是一个已解决的问题。早在 20 世纪 80 年代，德克萨斯仪器公司的 TMS(T1)和 T2 通用仪器公司的 sp 0256(T3)线性预测编码(T4 LPC(T5))语音芯片就使用了一种相当粗糙的人类声道来合成听起来像人类的声音。

在这中间的几年里。LPC 已经变得越来越适用于语音合成，同时也适用于语音编码和传输。通过使用现实生活中人类的声音作为 LPC 声道的基础，虚拟助手还可以在声音之间切换，允许 Siri、Cortana 等。听起来无论性别和种族对最终用户最有吸引力。

希望在未来几十年内，我们可以让语音识别和语音合成一样有效，甚至可能赋予这些虚拟助手一点真正的智能。