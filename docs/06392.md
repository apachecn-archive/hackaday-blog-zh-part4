# 使用 Valgrind 分析代码中的瓶颈可以让程序运行得更快，耗电更少

> 原文：<https://hackaday.com/2020/05/20/using-valgrind-to-analyze-code-for-bottlenecks-makes-faster-less-power-hungry-programs/>

优化代码的合适时机是什么？这是一个非常好的问题，通常可以归结为两个答案。第一个答案是从良好的代码设计开始，因为“优化”并不意味着“修正糟糕的设计决策”。第二个答案是，它应该在应用程序经过充分调试，并且其开发人员有感到厌烦的风险之后发生。

基于对应用程序有意义的东西，优化也应该有一个目标。它需要更快地处理数据吗？它应该减少通过网络或磁盘发送的数据吗？难道不应该检查一下内存使用情况吗？这些 CPU 缓存中到底发生了什么，导致单核的性能有时会大幅下降？

所有这些都可以使用 Valgrind 套件中的工具进行分析，包括 Cachegrind、Callgrind、DHAT 和 Massif。

## 保持这些核心冷却

现代处理器在设计时考虑到了低功耗，无论它们是针对服务器、台式机系统还是嵌入式应用。这实质上意味着它们在不做任何工作(空闲循环)时处于低功耗状态，一些 CPU 和微控制器会关闭不使用的芯片部分的电源。因此，处理器要做的事情越多，消耗的能量就越多，温度就越高。

由于更有效的算法或更少的抽象，需要更少指令来执行相同任务的代码不仅运行起来更酷，而且更快。这意味着，对于用户来说，体验不仅是任务完成得更快，而且设备变得不那么热，风扇噪音也更少。如果是电池供电，电池充电一次也能使用更长时间。基本上大家都会更开心。

这里选择的武器是[卡奇研磨](https://valgrind.org/docs/manual/cg-manual.html)和[卡奇研磨](https://valgrind.org/docs/manual/cl-manual.html)。尽管堆概要分析(本文稍后将介绍)对于节能也很有用，但主要的焦点应该是处理器。这意味着我们需要知道我们的代码在做什么，特别是我们代码的哪些部分运行得最频繁，因为这些是优化的主要目标。

## 追踪那些电话

运行 Cachegrind 和 Callgrind 相当简单。只需传递可执行文件的名称和它需要的任何标志，以及您希望使用的工具:

```
$ valgrind --tool=callgrind my_program 

```

这个命令将为我们名为 *my_program* 的程序启动 Callgrind 工具。可选地，我们也可以让 Callgrind 用`--simulate-cache=yes`模拟 CPU 缓存。运行时，Callgrind 生成一个名为`callgrind.out.<pid>`的输出文件，其中`<pid>`是应用程序运行时的进程 ID。然后，该文件被转换为人类可读的格式:

$ callgrind_annotate callgrind.out. <pid>> callgrind00.txt</pid>

这将生成一个文件，其中包含(除了其他内容之外)一个函数调用摘要，该摘要按照特定函数的执行时间进行排序，很明显，如果对该函数进行优化，可以获得很高的速度。

正如斯坦福大学的这篇文章中的[所解释的，高速缓存模拟的使用增加了关于高速缓存命中/未命中的细节:](https://web.stanford.edu/class/cs107/resources/callgrind)

*   `Ir` : I 缓存读取(执行的指令)
*   `I1mr` : I1 高速缓存读取未命中(指令不在 I1 高速缓存中，而是在 L2)
*   `I2mr` : L2 高速缓存指令读取未命中(指令不在 I1 或 L2 高速缓存中，必须从内存中取出)
*   `Dr` : D 缓存读取(内存读取)
*   `D1mr` : D1 高速缓存读取未命中(数据位置不在 D1 高速缓存中，而是在 L2)
*   `D2mr` : L2 高速缓存数据读取未命中(位置不在 D1 或 L2)
*   `Dw` : D 缓存写入(内存写入)
*   `D1mw` : D1 高速缓存写未命中(位置不在 D1 高速缓存中，而是在 L2)
*   `D2mw` : L2 高速缓存数据写入未命中(位置不在 D1 或 L2)

在一个算法或循环中看到大量缓存未命中将是一个强烈的提示，需要对其进行优化，以在缓存中占用更少的数据，采用预取来防止缓存未命中，或者采取适用于相关代码的其他措施。

使用 Cachegrind 与 Callgrind 非常相似，只是 Cachegrind 首先关注 CPU 缓存，其次才是函数调用。这应该很明显，根据一个人最迫切的问题，从这两个工具中选择哪一个。

## 用更少的内存做更多的事情

尽管计算机甚至微控制器通常以高速缓存和主系统内存(RAM)的形式提供比 20 世纪 90 年代的开发人员所能想象的更多的内存，但 RAM 有两个缺点:

*   RAM 不是无限的；在某个时候，堆空间将会耗尽。最好的情况是，只是您的应用程序被操作系统终止，而不是整个操作系统(或 RTOS)退出并导致整个系统出现一连串故障。
*   主动 RAM 消耗功率。动态 RAM (DRAM)模块的每个部分都必须不断刷新，以便保留存储值的电容电荷。对于电池供电的设备来说，这是一个特别重要的问题。

减少使用的内存量不仅会影响系统 RAM，还会有助于 CPU 处理单元和 RAM 之间的缓存。更少的数据意味着更少的缓存未命中和延迟，因为内存子系统会争先恐后地将请求的数据从 RAM 移动到 L3、L2 和(通常)L1 缓存。

虽然强大的 Xeon 或 Epyc 服务器处理器往往拥有 128 MB(或更多)的三级高速缓存，但一个常用的 ARM 处理器，如 Raspberry Pi 3(BCM 2837 SoC)[中的处理器，每个处理器都有 16 kB L1 高速缓存用于数据和指令，](https://www.raspberrypi.org/forums/viewtopic.php?t=145811)以及 512 kB L2 高速缓存。这里没有 L3 缓存。除非您的应用程序使用的总内存(堆栈和堆)少于 512 kB，否则系统 RAM 会定期被占用，这会严重影响应用程序的性能。

这里要做的一个区别是，每个应用程序都倾向于将数据存储在 RAM 中——无论是在堆中还是在堆栈中——这些数据可能被定期访问，也可能只是偶尔被访问。使用 Valgrind 的 [Massif](https://valgrind.org/docs/manual/ms-manual.html) 和 [DHAT](https://valgrind.org/docs/manual/dh-manual.html) 工具，很容易找出堆上这些数据的使用模式，以及哪些数据根本不需要再存储。

## 计算数字

Massif 是这两个工具中最容易使用的，只需在命令行中调用一次:

```
$ valgrind --tool=massif my_program

```

这将运行应用程序并输出到文件`massif.out.<pid>`，其中< pid >是应用程序被执行时的进程 id。在使用 Massif 收集的数据之前，我们首先必须对其进行处理:

```
$ ms_print massif.out.<pid> > massif00.txt

```

这将把 ms_print 实用程序的输出定向到一个文件中，该文件以人类可读的形式提供了详细信息。它包含一个堆使用随时间变化的图表，就像 Massif 文档中的这个示例:

```
    MB
3.952^                                                                    # 
     |                                                                   @#:
     |                                                                 :@@#:
     |                                                            @@::::@@#: 
     |                                                            @ :: :@@#::
     |                                                          @@@ :: :@@#::
     |                                                       @@:@@@ :: :@@#::
     |                                                    :::@ :@@@ :: :@@#::
     |                                                    : :@ :@@@ :: :@@#::
     |                                                  :@: :@ :@@@ :: :@@#:: 
     |                                                @@:@: :@ :@@@ :: :@@#:::
     |                           :       ::         ::@@:@: :@ :@@@ :: :@@#:::
     |                        :@@:    ::::: ::::@@@:::@@:@: :@ :@@@ :: :@@#:::
     |                     ::::@@:  ::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
     |                    @: ::@@:  ::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
     |                    @: ::@@:  ::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
     |                    @: ::@@:::::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
     |                ::@@@: ::@@:: ::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
     |             :::::@ @: ::@@:: ::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
     |           @@:::::@ @: ::@@:: ::: ::::::: @  :::@@:@: :@ :@@@ :: :@@#:::
   0 +----------------------------------------------------------------------->Mi
     0                                                                   626.4

Number of snapshots: 63
 Detailed snapshots: [3, 4, 10, 11, 15, 16, 29, 33, 34, 36, 39, 41,
                      42, 43, 44, 49, 50, 51, 53, 55, 56, 57 (peak)]

```

该图显示了 KDE 的 Konquerer 网络浏览器启动并运行一段时间后的情况。纵轴显示堆使用情况(以兆字节为单位)，横轴显示自应用程序启动以来已经执行的指令数。通过这种方式，用户可以了解堆的使用情况，图中的每个部分在文件中有更详细的描述，例如:

```
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
 15         21,112           19,096           19,000            96            0
 16         22,120           18,088           18,000            88            0
 17         23,128           17,080           17,000            80            0
 18         24,136           16,072           16,000            72            0
 19         25,144           15,064           15,000            64            0
 20         26,152           14,056           14,000            56            0
 21         27,160           13,048           13,000            48            0
 22         28,168           12,040           12,000            40            0
 23         29,176           11,032           11,000            32            0
 24         30,184           10,024           10,000            24            0
99.76% (10,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->79.81% (8,000B) 0x80483C2: g (example.c:5)
| ->39.90% (4,000B) 0x80483E2: f (example.c:11)
| | ->39.90% (4,000B) 0x8048431: main (example.c:23)
| |   
| ->39.90% (4,000B) 0x8048436: main (example.c:25)
|   
->19.95% (2,000B) 0x80483DA: f (example.c:10)
| ->19.95% (2,000B) 0x8048431: main (example.c:23)
|   
->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)

```

第一列是片号，详细的片被展开，显示堆中特定数据占用的堆空间的百分比，以及它在代码中的分配位置。显然，为了充分利用这一功能，需要用包含的调试符号(GCC 的-g 选项)来编译应用程序。

DHAT 的使用类似于 Massif，但它输出为 JSON 格式，需要基于浏览器的查看器( *dh_view.html* )来实际分析数据。与 Massif 相比，DHAT 可以提供更多关于堆中已分配数据的详细信息，包括从未完全使用的分配等信息。这是否有必要取决于人们期望什么样的优化。

## 保持工具箱装满

在之前查看了 Valgrind 套件中的其他常用工具之后，您应该对何时使用 Valgrind 来协助调试和优化工作有了一个很好的想法。尽管它们都是非常有用的工具，但它们并不是调试分析工具的全部。每个有经验的开发人员都知道，重要的是知道何时使用每种方法。

有时，只需要一个简单的调试器或应用程序内部的可靠日志来解决最严重的问题。只有当这没有帮助时，才是时候开始打破沉重的工具，并警告说，强大的工具带来了解释数据的巨大责任。做出正确决策和得出正确结论的经验和知识与其他工具一样重要。