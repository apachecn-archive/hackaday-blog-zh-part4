# 这个淘气的家伙欺骗了系统

> 原文:[https://hack aday . com/2018/11/11/the-naughty-ais-that-gamed-the-system/](https://hackaday.com/2018/11/11/the-naughty-ais-that-gamed-the-system/)

人工智能(AI)在过去几年里经历了某种复兴。对神经网络和其他技术已经有了大量的研究，通常是围绕着教授人工智能系统来实现某些目标或指标。然而，这种训练方法充满了危险，因为就像电影中一样，计算机并不总是公平的。

通常情况下，人工智能会完全按照它被告知的去做，而不是完全按照你的意图去做。就像一个狡猾的孩子，他会很高兴*上床*睡觉，但实际上不会睡觉，这可能会导致意想不到的，而且往往非常滑稽的结果。[【维多利亚】已经创建了一个关于这个](https://docs.google.com/spreadsheets/u/1/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml)的学术参考的主列表。

该清单涵盖了广泛的案例。有一种有趣的进化算法，旨在创造能够高速移动的生物，它只是产生了非常高的生物，通过摔倒来产生这些速度。更令人担忧的是，训练有素的人工智能可以识别有毒和可食用的蘑菇，它只是发现了这两种蘑菇以交替顺序出现的事实。这最终成为现实世界中一个不可靠的模型。类似地，设计用于评估皮肤癌恶性程度的模型确定用标尺拍摄的病变更有可能是癌性的。

[Victoria]称之为“规范游戏”。人们可以将经典科幻故事与“机器人法则”相提并论，机器人将这些法则发挥到了极致，往往在这个过程中造成巨大伤害。这是一个有趣的讨论，讨论了在没有不良副作用的情况下训练人工智能系统以实现其既定目标的难度。

我们之前已经在这个领域看到了大量的工作——[像这样在电路设计中使用进化算法](https://hackaday.com/2012/07/09/on-not-designing-circuits-with-evolutionary-algorithms/)。